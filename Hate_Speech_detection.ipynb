{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFDIJu3DzTYu"
      },
      "outputs": [],
      "source": [
        "import pandas as panda\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import *\n",
        "import string\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn\n",
        "from textstat.textstat import *\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import numpy as np\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer as VS\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = panda.read_csv(\"HateSpeechData.csv\")\n",
        "dataset"
      ],
      "metadata": {
        "id": "DBCTPGx9zdDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding text-length as a field in the dataset\n",
        "dataset['text length'] = dataset['tweet'].apply(len)\n",
        "print(dataset.head())"
      ],
      "metadata": {
        "id": "mlDcdVHmzfzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding text-length as a field in the dataset\n",
        "dataset['text length'] = dataset['tweet'].apply(len)\n",
        "print(dataset.head())"
      ],
      "metadata": {
        "id": "tmWv7DXNzhdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# collecting only the tweets from the csv file into a variable name tweet\n",
        "tweet=dataset.tweet"
      ],
      "metadata": {
        "id": "ml05ho7DzjBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 1. Removal of punctuation and capitlization\n",
        "## 2. Tokenizing\n",
        "## 3. Removal of stopwords\n",
        "## 4. Stemming\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
        "\n",
        "#extending the stopwords to include other words used in twitter such as retweet(rt) etc.\n",
        "other_exclusions = [\"#ff\", \"ff\", \"rt\"]\n",
        "stopwords.extend(other_exclusions)\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def preprocess(tweet):\n",
        "\n",
        "    # removal of extra spaces\n",
        "    regex_pat = re.compile(r'\\s+')\n",
        "    tweet_space = tweet.str.replace(regex_pat, ' ')\n",
        "\n",
        "    # removal of @name[mention]\n",
        "    regex_pat = re.compile(r'@[\\w\\-]+')\n",
        "    tweet_name = tweet_space.str.replace(regex_pat, '')\n",
        "\n",
        "    # removal of links[https://abc.com]\n",
        "    giant_url_regex =  re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
        "            '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
        "    tweets = tweet_name.str.replace(giant_url_regex, '')\n",
        "\n",
        "    # removal of punctuations and numbers\n",
        "    punc_remove = tweets.str.replace(\"[^a-zA-Z]\", \" \")\n",
        "    # remove whitespace with a single space\n",
        "    newtweet=punc_remove.str.replace(r'\\s+', ' ')\n",
        "    # remove leading and trailing whitespace\n",
        "    newtweet=newtweet.str.replace(r'^\\s+|\\s+?$','')\n",
        "    # replace normal numbers with numbr\n",
        "    newtweet=newtweet.str.replace(r'\\d+(\\.\\d+)?','numbr')\n",
        "    # removal of capitalization\n",
        "    tweet_lower = newtweet.str.lower()\n",
        "\n",
        "    # tokenizing\n",
        "    tokenized_tweet = tweet_lower.apply(lambda x: x.split())\n",
        "\n",
        "    # removal of stopwords\n",
        "    tokenized_tweet=  tokenized_tweet.apply(lambda x: [item for item in x if item not in stopwords])\n",
        "\n",
        "    # stemming of the tweets\n",
        "    tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x])\n",
        "\n",
        "    for i in range(len(tokenized_tweet)):\n",
        "        tokenized_tweet[i] = ' '.join(tokenized_tweet[i])\n",
        "        tweets_p= tokenized_tweet\n",
        "\n",
        "    return tweets_p\n",
        "\n",
        "processed_tweets = preprocess(tweet)\n",
        "\n",
        "dataset['processed_tweets'] = processed_tweets\n",
        "print(dataset[[\"tweet\",\"processed_tweets\"]].head(10))"
      ],
      "metadata": {
        "id": "Ioxd-XP0ztTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizing which of the word is most commonly used in the twitter dataset\n",
        "from wordcloud import WordCloud\n",
        "# imshow-Display data as an image\n",
        "# interpolation - https://matplotlib.org/3.2.1/gallery/images_contours_and_fields/interpolation_methods.html\n",
        "all_words = ' '.join([text for text in dataset['processed_tweets'] ])\n",
        "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words)\n",
        "#random=0.30\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GSbTELFszyAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizing which of the word is most commonly used for hatred speech\n",
        "hatred_words = ' '.join([text for text in dataset['processed_tweets'][dataset['class'] == 0]])\n",
        "wordcloud = WordCloud(width=800, height=500,\n",
        "random_state=21, max_font_size=110).generate(hatred_words)\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DVAx77QTzzgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizing which of the word is most commonly used for offensive speech\n",
        "offensive_words = ' '.join([text for text in dataset['processed_tweets'][dataset['class'] == 1]])\n",
        "wordcloud = WordCloud(width=800, height=500,\n",
        "random_state=21, max_font_size=110).generate(offensive_words)\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pvxf6Bkwz01H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TF-IDF Features-F1\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2),max_df=0.75, min_df=5, max_features=10000)\n",
        "\n",
        "# TF-IDF feature matrix\n",
        "tfidf = tfidf_vectorizer.fit_transform(dataset['processed_tweets'] )\n",
        "tfidf"
      ],
      "metadata": {
        "id": "uoWOEd9gz2R6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you don't specify the random_state in the code,\n",
        "# then every time you run(execute) your code a new random value is generated\n",
        "# and the train and test datasets would have different values each time.\n",
        "X = tfidf\n",
        "y = dataset['class'].astype(int)\n",
        "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
        "model = LogisticRegression().fit(X_train_tfidf,y_train)\n",
        "y_preds = model.predict(X_test_tfidf)\n",
        "report = classification_report( y_test, y_preds )\n",
        "print(report)\n",
        "acc=accuracy_score(y_test,y_preds)\n",
        "print(\"Logistic Regression, Accuracy Score:\" , acc)"
      ],
      "metadata": {
        "id": "V6a0uUSez37k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
        "rf=RandomForestClassifier()\n",
        "rf.fit(X_train_tfidf,y_train)\n",
        "y_preds = rf.predict(X_test_tfidf)\n",
        "acc1=accuracy_score(y_test,y_preds)\n",
        "report = classification_report( y_test, y_preds )\n",
        "print(report)\n",
        "print(\"Random Forest, Accuracy Score:\",acc1)"
      ],
      "metadata": {
        "id": "vsjFe79uz5wD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X.toarray(), y, random_state=42, test_size=0.2)\n",
        "nb=GaussianNB()\n",
        "nb.fit(X_train_tfidf,y_train)\n",
        "y_preds = nb.predict(X_test_tfidf)\n",
        "acc2=accuracy_score(y_test,y_preds)\n",
        "report = classification_report( y_test, y_preds )\n",
        "print(report)\n",
        "print(\"Naive Bayes, Accuracy Score:\",acc2)"
      ],
      "metadata": {
        "id": "yoPlpcCtz8gA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "support =LinearSVC(random_state=20)\n",
        "support.fit(X_train_tfidf,y_train)\n",
        "y_preds = support.predict(X_test_tfidf)\n",
        "acc3=accuracy_score(y_test,y_preds)\n",
        "report = classification_report( y_test, y_preds )\n",
        "print(report)\n",
        "print(\"SVM, Accuracy Score:\" , acc3)"
      ],
      "metadata": {
        "id": "LAWkWUwBz-Uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "objects = ('Logistic', 'RandomForest', 'Naive_bayes', 'SVM')\n",
        "y_pos = np.arange(len(objects))\n",
        "performance = [acc,acc1,acc2,acc3]\n",
        "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
        "plt.xticks(y_pos, objects)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Algorithm Comparision for F1')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a_q1oDWgz_P4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_analyzer = VS()\n",
        "def count_tags(tweet_c):\n",
        "\n",
        "    space_pattern = '\\s+'\n",
        "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
        "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
        "    mention_regex = '@[\\w\\-]+'\n",
        "    hashtag_regex = '#[\\w\\-]+'\n",
        "    parsed_text = re.sub(space_pattern, ' ', tweet_c)\n",
        "    parsed_text = re.sub(giant_url_regex, 'URLHERE', parsed_text)\n",
        "    parsed_text = re.sub(mention_regex, 'MENTIONHERE', parsed_text)\n",
        "    parsed_text = re.sub(hashtag_regex, 'HASHTAGHERE', parsed_text)\n",
        "    return(parsed_text.count('URLHERE'),parsed_text.count('MENTIONHERE'),parsed_text.count('HASHTAGHERE'))\n",
        "\n",
        "def sentiment_analysis(tweet):\n",
        "    sentiment = sentiment_analyzer.polarity_scores(tweet)\n",
        "    twitter_objs = count_tags(tweet)\n",
        "    features = [sentiment['neg'], sentiment['pos'], sentiment['neu'], sentiment['compound'],twitter_objs[0], twitter_objs[1],\n",
        "                twitter_objs[2]]\n",
        "    #features = pandas.DataFrame(features)\n",
        "    return features\n",
        "\n",
        "def sentiment_analysis_array(tweets):\n",
        "    features=[]\n",
        "    for t in tweets:\n",
        "        features.append(sentiment_analysis(t))\n",
        "    return np.array(features)\n",
        "\n",
        "final_features = sentiment_analysis_array(tweet)\n",
        "#final_features\n",
        "\n",
        "new_features = panda.DataFrame({'Neg':final_features[:,0],'Pos':final_features[:,1],'Neu':final_features[:,2],'Compound':final_features[:,3],\n",
        "                            'url_tag':final_features[:,4],'mention_tag':final_features[:,5],'hash_tag':final_features[:,6]})\n",
        "new_features"
      ],
      "metadata": {
        "id": "Np8hbloc0BA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# F2-Conctaenation of tf-idf scores and sentiment scores\n",
        "tfidf_a = tfidf.toarray()\n",
        "modelling_features = np.concatenate([tfidf_a,final_features],axis=1)\n",
        "modelling_features.shape"
      ],
      "metadata": {
        "id": "KxaXgYS90EcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Running the model Using TFIDF with some features from sentiment analysis\n",
        "\n",
        "X = panda.DataFrame(modelling_features)\n",
        "y = dataset['class'].astype(int)\n",
        "X_train_bow, X_test_bow, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
        "\n",
        "model = LogisticRegression().fit(X_train_bow,y_train)\n",
        "y_preds = model.predict(X_test_bow)\n",
        "report = classification_report( y_test, y_preds )\n",
        "print(report)\n",
        "acc=accuracy_score(y_test,y_preds)\n",
        "print(\"Logistic Regression,Accuracy Score:\" , acc)"
      ],
      "metadata": {
        "id": "_j72rW0x0F96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = panda.DataFrame(modelling_features)\n",
        "y = dataset['class'].astype(int)\n",
        "X_train_bow, X_test_bow, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
        "rf=RandomForestClassifier()\n",
        "rf.fit(X_train_bow,y_train)\n",
        "y_preds = rf.predict(X_test_bow)\n",
        "acc1=accuracy_score(y_test,y_preds)\n",
        "report = classification_report( y_test, y_preds )\n",
        "print(report)\n",
        "print(\"Random Forest, Accuracy Score:\",acc1)"
      ],
      "metadata": {
        "id": "xupchRyH0HVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = panda.DataFrame(modelling_features)\n",
        "y = dataset['class'].astype(int)\n",
        "X_train_bow, X_test_bow, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
        "nb=GaussianNB()\n",
        "nb.fit(X_train_bow,y_train)\n",
        "y_preds = nb.predict(X_test_bow)\n",
        "acc2=accuracy_score(y_test,y_preds)\n",
        "report = classification_report( y_test, y_preds )\n",
        "print(report)\n",
        "print(\"Naive Bayes, Accuracy Score:\",acc2)"
      ],
      "metadata": {
        "id": "-0BoqYQT0Iph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = panda.DataFrame(modelling_features)\n",
        "y = dataset['class'].astype(int)\n",
        "X_train_bow, X_test_bow, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
        "support =LinearSVC(random_state=20)\n",
        "support.fit(X_train_bow,y_train)\n",
        "y_preds = support.predict(X_test_bow)\n",
        "acc3=accuracy_score(y_test,y_preds)\n",
        "report = classification_report( y_test, y_preds )\n",
        "print(report)\n",
        "print(\"SVM, Accuracy Score:\" , acc3)"
      ],
      "metadata": {
        "id": "LhSbGIw_0Klg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "objects = ('Logistic', 'RandomForest', 'Naive_bayes', 'SVM')\n",
        "y_pos = np.arange(len(objects))\n",
        "performance = [acc,acc1,acc2,acc3]\n",
        "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
        "plt.xticks(y_pos, objects)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Algorithm Comparision for F2')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PNxmtwyD0Kgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create doc2vec vector columns\n",
        "# Initialize and train the model\n",
        "from gensim.test.utils import common_texts\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "#The input for a Doc2Vec model should be a list of TaggedDocument(['list','of','word'], [TAG_001]).\n",
        "#A good practice is using the indexes of sentences as the tags.\n",
        "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(dataset[\"processed_tweets\"].apply(lambda x: x.split(\" \")))]\n",
        "\n",
        "# train a Doc2Vec model with our text data\n",
        "# window- The maximum distance between the current and predicted word within a sentence.\n",
        "# mincount-Ignores all words with total frequency lower than this.\n",
        "# workers -Use these many worker threads to train the model\n",
        "#  Training Model - distributed bag of words (PV-DBOW) is employed.\n",
        "model = Doc2Vec(documents, ,vector_size=5, window=2, min_count=1, workers=4)\n",
        "\n",
        "#infer_vector - Infer a vector for given post-bulk training document.\n",
        "# Syntax- infer_vector(doc_words, alpha=None, min_alpha=None, epochs=None, steps=None)\n",
        "# doc_words-A document for which the vector representation will be inferred.\n",
        "\n",
        "# transform each document into a vector data\n",
        "doc2vec_df = dataset[\"processed_tweets\"].apply(lambda x: model.infer_vector(x.split(\" \"))).apply(panda.Series)\n",
        "doc2vec_df.columns = [\"doc2vec_vector_\" + str(x) for x in doc2vec_df.columns]\n",
        "doc2vec_df"
      ],
      "metadata": {
        "id": "e_mqeWDE0PkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# conctaenation of tf-idf scores, sentiment scores and doc2vec columns\n",
        "modelling_features = np.concatenate([tfidf_a,final_features,doc2vec_df],axis=1)\n",
        "modelling_features.shape"
      ],
      "metadata": {
        "id": "YH87Xd4e0P_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = panda.DataFrame(modelling_features)\n",
        "y = dataset['class'].astype(int)\n",
        "X_train_bow, X_test_bow, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
        "\n",
        "model = LogisticRegression().fit(X_train_bow,y_train)\n",
        "y_preds = model.predict(X_test_bow)\n",
        "report = classification_report( y_test, y_preds )\n",
        "print(report)\n",
        "acc=accuracy_score(y_test,y_preds)\n",
        "print(\"Logistic Regression, Accuracy Score:\" , acc)"
      ],
      "metadata": {
        "id": "OTX0Xxb10TsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = panda.DataFrame(modelling_features)\n",
        "y = dataset['class'].astype(int)\n",
        "X_train_bow, X_test_bow, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
        "rf=RandomForestClassifier()\n",
        "rf.fit(X_train_bow,y_train)\n",
        "y_preds = rf.predict(X_test_bow)\n",
        "acc1=accuracy_score(y_test,y_preds)\n",
        "report = classification_report( y_test, y_preds )\n",
        "print(report)\n",
        "print(\"Random Forest, Accuracy Score:\",acc1)"
      ],
      "metadata": {
        "id": "TXai8JAu0Vmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = panda.DataFrame(modelling_features)\n",
        "y = dataset['class'].astype(int)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
        "nb=GaussianNB()\n",
        "nb.fit(X_train,y_train)\n",
        "y_preds = nb.predict(X_test)\n",
        "acc2=accuracy_score(y_test,y_preds)\n",
        "report = classification_report( y_test, y_preds )\n",
        "print(report)\n",
        "print(\"Naive Bayes, Accuracy Score:\",acc2)"
      ],
      "metadata": {
        "id": "uTGi3-jW0XFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = panda.DataFrame(modelling_features)\n",
        "y = dataset['class'].astype(int)\n",
        "X_train_bow, X_test_bow, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
        "support =LinearSVC(random_state=20)\n",
        "support.fit(X_train_bow,y_train)\n",
        "y_preds = support.predict(X_test_bow)\n",
        "acc3=accuracy_score(y_test,y_preds)\n",
        "report = classification_report( y_test, y_preds )\n",
        "print(report)\n",
        "print(\"SVM, Accuracy Score:\" , acc3)"
      ],
      "metadata": {
        "id": "InwingUh0Y5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "objects = ('Logistic', 'RandomForest', 'Naive_bayes', 'SVM')\n",
        "y_pos = np.arange(len(objects))\n",
        "performance = [acc,acc1,acc2,acc3]\n",
        "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
        "plt.xticks(y_pos, objects)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Algorithm Comparision')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2SjVYaE70bLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using TFIDF with sentiment scores,doc2vec and enhanced features\n",
        "def additional_features(tweet):\n",
        "\n",
        "    syllables = textstat.syllable_count(tweet)\n",
        "    num_chars = sum(len(w) for w in tweet)\n",
        "    num_chars_total = len(tweet)\n",
        "    num_words = len(tweet.split())\n",
        "    # avg_syl = total syllables/ total words\n",
        "    avg_syl = round(float((syllables+0.001))/float(num_words+0.001),4)\n",
        "    num_unique_terms = len(set(tweet.split()))\n",
        "\n",
        "    #  Flesch–Kincaid readability tests are readability tests\n",
        "    #  designed to indicate how difficult a passage in English is to understand.\n",
        "    # There are two tests, the Flesch Reading Ease, and the Flesch–Kincaid Grade\n",
        "    # A text with a comparatively high score on FRE test should have a lower score on the FKRA test.\n",
        "    # Reference - https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests\n",
        "\n",
        "    ###Modified FK grade, where avg words per sentence is : just num words/1\n",
        "    FKRA = round(float(0.39 * float(num_words)/1.0) + float(11.8 * avg_syl) - 15.59,1)\n",
        "    ##Modified FRE score, where sentence fixed to 1\n",
        "    FRE = round(206.835 - 1.015*(float(num_words)/1.0) - (84.6*float(avg_syl)),2)\n",
        "\n",
        "    add_features=[FKRA, FRE,syllables, avg_syl, num_chars, num_chars_total, num_words,\n",
        "                num_unique_terms]\n",
        "    return add_features\n",
        "\n",
        "def get_additonal_feature_array(tweets):\n",
        "    features=[]\n",
        "    for t in tweets:\n",
        "        features.append(additional_features(t))\n",
        "    return np.array(features)\n",
        "\n",
        "fFeatures = get_additonal_feature_array(processed_tweets)\n",
        "tfidf_a = tfidf.toarray()\n",
        "modelling_features_enhanced = np.concatenate([tfidf_a,final_features,doc2vec_df,fFeatures],axis=1)\n",
        "modelling_features_enhanced.shape"
      ],
      "metadata": {
        "id": "e1GJ3sqw0eJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Running the model Using TFIDF with enhanced features\n",
        "\n",
        "X = panda.DataFrame(modelling_features_enhanced)\n",
        "y = dataset['class'].astype(int)\n",
        "X_train_features, X_test_features, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.2)\n",
        "\n",
        "model = LogisticRegression().fit(X_train_features,y_train)\n",
        "y_preds = model.predict(X_test_features)\n",
        "report = classification_report( y_test, y_preds )\n",
        "print(report)\n",
        "acc=accuracy_score(y_test,y_preds)\n",
        "print(\"Logistic Regression, Accuracy Score:\" , acc)"
      ],
      "metadata": {
        "id": "yBEJnFUt0gH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion Matrix for TFIDF with additional features\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix = confusion_matrix(y_test,y_preds)\n",
        "matrix_proportions = np.zeros((3,3))\n",
        "for i in range(0,3):\n",
        "    matrix_proportions[i,:] = confusion_matrix[i,:]/float(confusion_matrix[i,:].sum())\n",
        "names=['Hate','Offensive','Neither']\n",
        "confusion_df = panda.DataFrame(matrix_proportions, index=names,columns=names)\n",
        "plt.figure(figsize=(5,5))\n",
        "seaborn.heatmap(confusion_df,annot=True,annot_kws={\"size\": 12},cmap='YlGnBu',cbar=False, square=True,fmt='.2f')\n",
        "plt.ylabel(r'True Value',fontsize=14)\n",
        "plt.xlabel(r'Predicted Value',fontsize=14)\n",
        "plt.tick_params(labelsize=12)"
      ],
      "metadata": {
        "id": "NEWqQyCl0iTQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}